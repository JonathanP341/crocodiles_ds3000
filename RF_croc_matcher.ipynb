{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e646cb84",
   "metadata": {},
   "source": [
    "### Random Forest Crocodile Matcher (RF_croc_matcher.ipynb) \n",
    "\n",
    "This notebook builds a Random Forest model to classify the **Conservation Status** of crocodiles using the provided dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24955a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core data tools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Model and training utilities\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, log_loss, classification_report, confusion_matrix, roc_auc_score\n",
    ")\n",
    "\n",
    "# Model\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb06a49f",
   "metadata": {},
   "source": [
    "#### 1. Dataset Overview & Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d33411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "croc_df = pd.read_csv(\"crocodile_dataset.csv\")\n",
    "\n",
    "# Preview first rows\n",
    "display(croc_df.head())\n",
    "\n",
    "# Display dataset information\n",
    "print(\"\\nDataset Info:\")\n",
    "croc_df.info()\n",
    "\n",
    "# Display missing values in table format\n",
    "print(\"\\nMissing values:\")\n",
    "print(croc_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5d70c3",
   "metadata": {},
   "source": [
    "#### 2. Target Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a690367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show class distribution of the target variable\n",
    "print(\"Conservation Status counts:\")\n",
    "print(croc_df[\"Conservation Status\"].value_counts())\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.countplot(data=croc_df, x=\"Conservation Status\")\n",
    "plt.title(\"Distribution of Conservation Status\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6a8ec6",
   "metadata": {},
   "source": [
    "#### 3. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089325b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the disputed species row\n",
    "croc_df = croc_df[croc_df[\"Common Name\"] != \"Borneo Crocodile (disputed)\"]\n",
    "\n",
    "# Columns that reveal species or are irrelevant\n",
    "drop_cols = [\n",
    "    \"Observation ID\",     # random ID, no predictive value\n",
    "    \"Observer Name\",      # irrelevant to conservation status\n",
    "    \"Notes\",              # unstructured text not used in project\n",
    "    \"Scientific Name\",    # reveals species\n",
    "    \"Common Name\",        # reveals species\n",
    "    \"Family\",             # related to species identity\n",
    "    \"Genus\"               # related to species identity\n",
    "]\n",
    "\n",
    "# Drop unwanted columns\n",
    "clean_df = croc_df.drop(columns=drop_cols)\n",
    "\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddf3fce",
   "metadata": {},
   "source": [
    "#### 4. Process Date & Define Features/Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14e901a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string date to datetime object\n",
    "clean_df[\"Date\"] = pd.to_datetime(clean_df[\"Date of Observation\"], format=\"%d-%m-%Y\")\n",
    "\n",
    "# Extract year only (day/month unnecessary for our prediction task)\n",
    "clean_df[\"Year\"] = clean_df[\"Date\"].dt.year\n",
    "\n",
    "# Remove raw date columns\n",
    "clean_df = clean_df.drop(columns=[\"Date\", \"Date of Observation\"])\n",
    "\n",
    "# Define target (y) and features (X)\n",
    "target = \"Conservation Status\"\n",
    "y = clean_df[target]\n",
    "X = clean_df.drop(columns=[target])\n",
    "\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e399567",
   "metadata": {},
   "source": [
    "#### 5. Train / Test Split & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d609e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified split preserves class proportions in train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Identify numeric and categorical columns for preprocessing\n",
    "num_cols = [\"Observed Length (m)\", \"Observed Weight (kg)\", \"Year\"]\n",
    "cat_cols = [\"Age Class\", \"Sex\", \"Country/Region\", \"Habitat Type\"]\n",
    "\n",
    "# ColumnTransformer applies different preprocessing to numeric vs categorical columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), num_cols),      # scale numeric features\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"),   # convert categories to binary vectors\n",
    "         cat_cols)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e46055",
   "metadata": {},
   "source": [
    "#### 6. Random Forest Pipeline & Tuning Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7db934a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pipeline; preprocess first, then apply Random Forest\n",
    "rf_model = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Hyperparameter search space for GridSearchCV\n",
    "param_grid = {\n",
    "    \"model__n_estimators\": [100, 200, 300],   # number of trees\n",
    "    \"model__max_depth\": [None, 5, 10, 20],    # tree depth\n",
    "    \"model__max_features\": [\"sqrt\", \"log2\"],  # number of features to consider at each split\n",
    "    \"model__min_samples_split\": [2, 5, 10],   # internal node split threshold\n",
    "    \"model__min_samples_leaf\": [1, 2, 4]      # minimum leaf size\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dddb7bc",
   "metadata": {},
   "source": [
    "#### 7. Hyperparameter Tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440efc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup grid search with log-loss scoring and 5-fold cross-validation\n",
    "rf_grid = GridSearchCV(\n",
    "    estimator=rf_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"neg_log_loss\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit on training data\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "# Show the best discovered parameters\n",
    "rf_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c156956",
   "metadata": {},
   "source": [
    "#### 8. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5754d6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve best model from grid search\n",
    "best_rf = rf_grid.best_estimator_\n",
    "\n",
    "# Predict classes and prediction probabilities\n",
    "y_pred = best_rf.predict(X_test)\n",
    "y_proba = best_rf.predict_proba(X_test)\n",
    "\n",
    "# Accuracy, ROC AUC, and log-loss metrics\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"ROC-AUC (OVR):\", roc_auc_score(y_test, y_proba, multi_class=\"ovr\"))\n",
    "print(\"Log Loss:\", log_loss(y_test, y_proba))\n",
    "\n",
    "# Detailed per-class performance\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32654700",
   "metadata": {},
   "source": [
    "#### 9. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb07c7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot heatmap for easier interpretation\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75717839",
   "metadata": {},
   "source": [
    "#### 10. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83faca40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract trained RF model and fitted one-hot encoder\n",
    "rf_clf = best_rf.named_steps[\"model\"]\n",
    "ohe = best_rf.named_steps[\"preprocessor\"].named_transformers_[\"cat\"]\n",
    "\n",
    "# Get names of encoded categorical features\n",
    "cat_features = ohe.get_feature_names_out(cat_cols)\n",
    "\n",
    "# Combine numeric + encoded categorical names\n",
    "all_features = num_cols + list(cat_features)\n",
    "\n",
    "# Extract feature importance scores from Random Forest\n",
    "importances = rf_clf.feature_importances_\n",
    "\n",
    "# Print top 15 most important features\n",
    "indices = np.argsort(importances)[::-1][:15]\n",
    "\n",
    "print(\"Top 15 Important Features:\\n\")\n",
    "for idx in indices:\n",
    "    print(all_features[idx], \":\", importances[idx])\n",
    "\n",
    "# Plot top 15 feature importances\n",
    "sorted_idx = indices\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.barh([all_features[i] for i in sorted_idx], importances[sorted_idx])\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.title(\"Top 15 Most Important Features\")\n",
    "plt.gca().invert_yaxis()   # highest at top\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
