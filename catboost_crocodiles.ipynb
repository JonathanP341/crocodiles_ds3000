{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CatBoost Classification for Crocodile Species\n",
        "# Baseline and Bayesian tuning with Optuna for comparison with XGBoost\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import log_loss, accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
        "\n",
        "from catboost import CatBoostClassifier\n",
        "import optuna\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "\n",
        "# Load dataset from root CSV\n",
        "DATA_PATH = \"crocodile_dataset.csv\"\n",
        "raw_df = pd.read_csv(DATA_PATH)\n",
        "raw_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic EDA\n",
        "print(\"Shape:\", raw_df.shape)\n",
        "display(raw_df.head())\n",
        "print(\"\\nInfo:\")\n",
        "print(raw_df.info())\n",
        "\n",
        "print(\"\\nClass distribution (Common Name):\")\n",
        "print(raw_df['Common Name'].value_counts(normalize=True))\n",
        "\n",
        "# Example feature distribution plots for numeric columns\n",
        "numeric_cols = raw_df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "if numeric_cols:\n",
        "    raw_df[numeric_cols].hist(figsize=(12, 8))\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Correlation heatmap for numerical features\n",
        "if len(numeric_cols) <= 20 and len(numeric_cols) > 1:\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(raw_df[numeric_cols].corr(), annot=False, cmap='coolwarm')\n",
        "    plt.title('Correlation Heatmap (Numeric Features)')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preprocessing: remove contested species and leak features, then create train/val split\n",
        "DF = raw_df.copy()\n",
        "\n",
        "# Remove contested species to avoid taxonomic ambiguity\n",
        "CONTESTED_SPECIES_NAME = 'Borneo Crocodile (disputed)'\n",
        "if CONTESTED_SPECIES_NAME in DF['Common Name'].unique():\n",
        "    DF = DF[DF['Common Name'] != CONTESTED_SPECIES_NAME].copy()\n",
        "    print(f\"Removed contested species '{CONTESTED_SPECIES_NAME}', new shape: {DF.shape}\")\n",
        "\n",
        "# Drop columns that directly reveal the target (data leakage)\n",
        "leak_cols = [col for col in ['Observation ID', 'Scientific Name', 'Family', 'Genus', \n",
        "                              'Conservation Status', 'Observer Name', 'Notes'] if col in DF.columns]\n",
        "print(\"Dropping leak columns:\", leak_cols)\n",
        "DF = DF.drop(columns=leak_cols)\n",
        "\n",
        "# Extract and transform temporal features\n",
        "if 'Date of Observation' in DF.columns:\n",
        "    DF['Date of Observation'] = pd.to_datetime(DF['Date of Observation'], dayfirst=True, errors='coerce')\n",
        "    DF['Year'] = DF['Date of Observation'].dt.year\n",
        "    DF['Month'] = DF['Date of Observation'].dt.month\n",
        "    \n",
        "    # Normalize year using full dataset statistics before split\n",
        "    if DF['Year'].notna().any():\n",
        "        max_year = DF['Year'].max()\n",
        "        min_year = DF['Year'].min()\n",
        "        if max_year != min_year:\n",
        "            DF['Year'] = (DF['Year'] - min_year) / (max_year - min_year)\n",
        "    \n",
        "    # Sine transformation preserves cyclic nature of months\n",
        "    DF['Month'] = np.sin((np.pi * DF['Month']) / 12)\n",
        "    DF = DF.drop(columns=['Date of Observation'])\n",
        "\n",
        "# Define features and target (predicting Common Name)\n",
        "target_col = 'Common Name'\n",
        "X = DF.drop(columns=[target_col])\n",
        "y = DF[target_col]\n",
        "\n",
        "# Identify column types\n",
        "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "print(\"Categorical columns:\", categorical_cols)\n",
        "print(\"Numeric columns:\", numeric_cols)\n",
        "\n",
        "# Stratified train/validation split for consistent comparison\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=RANDOM_STATE,\n",
        "    stratify=y  # Preserve class distribution\n",
        ")\n",
        "\n",
        "print(f\"Train shape: {X_train.shape}, Valid shape: {X_valid.shape}\")\n",
        "print(f\"Number of classes: {len(y.unique())}\")\n",
        "\n",
        "# Encode labels for CatBoost (needs numeric labels for multi-class)\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_valid_encoded = label_encoder.transform(y_valid)\n",
        "n_classes = len(label_encoder.classes_)\n",
        "print(f\"Number of classes: {n_classes}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CatBoost Baseline Implementation\n",
        "print(\"=\"*70)\n",
        "print(\"CATBOOST BASELINE IMPLEMENTATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Identify categorical feature indices for CatBoost\n",
        "cat_features_indices = [i for i, col in enumerate(X_train.columns) \n",
        "                        if col in categorical_cols]\n",
        "\n",
        "print(f\"\\nCategorical features (indices): {cat_features_indices}\")\n",
        "print(f\"Categorical feature names: {[X_train.columns[i] for i in cat_features_indices]}\")\n",
        "\n",
        "# Baseline hyperparameters\n",
        "catboost_baseline = CatBoostClassifier(\n",
        "    iterations=100,\n",
        "    learning_rate=0.1,\n",
        "    depth=5,\n",
        "    loss_function='MultiClass',\n",
        "    random_seed=RANDOM_STATE,\n",
        "    verbose=False,\n",
        "    cat_features=cat_features_indices if cat_features_indices else None\n",
        ")\n",
        "\n",
        "catboost_baseline.fit(\n",
        "    X_train, y_train_encoded,\n",
        "    cat_features=cat_features_indices if cat_features_indices else None,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "# Evaluate baseline model\n",
        "catboost_baseline_proba = catboost_baseline.predict_proba(X_valid)\n",
        "catboost_baseline_pred_encoded = catboost_baseline.predict(X_valid)\n",
        "catboost_baseline_pred = label_encoder.inverse_transform(catboost_baseline_pred_encoded)\n",
        "\n",
        "catboost_baseline_logloss = log_loss(y_valid_encoded, catboost_baseline_proba)\n",
        "catboost_baseline_acc = accuracy_score(y_valid, catboost_baseline_pred)\n",
        "# Calculate AUC-ROC for multi-class (one-vs-rest macro-averaged)\n",
        "catboost_baseline_auc = roc_auc_score(y_valid_encoded, catboost_baseline_proba, multi_class='ovr', average='macro')\n",
        "\n",
        "print(f\"\\nCatBoost Baseline - Log Loss: {catboost_baseline_logloss:.4f}, Accuracy: {catboost_baseline_acc:.4f}, AUC-ROC: {catboost_baseline_auc:.4f}\")\n",
        "print(\"\\nConfusion matrix (CatBoost Baseline):\")\n",
        "print(confusion_matrix(y_valid, catboost_baseline_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_valid, catboost_baseline_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CatBoost with Optuna Hyperparameter Tuning\n",
        "SKIP_CATBOOST_TUNING = False  # Set to True to skip tuning (use baseline only)\n",
        "\n",
        "if not SKIP_CATBOOST_TUNING:\n",
        "    print(\"=\"*70)\n",
        "    print(\"CATBOOST OPTUNA TUNING\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"NOTE: This may take several minutes. Interrupt if needed.\")\n",
        "    print(\"You can skip this by setting SKIP_CATBOOST_TUNING = True above.\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    N_TRIALS_CAT = 30  # Same number of trials as XGBoost for fair comparison\n",
        "    MAX_ITERATIONS = 50  # Limited iterations during tuning to reduce computation time\n",
        "    \n",
        "    def catboost_objective(trial):\n",
        "        # Hyperparameter search space\n",
        "        params = {\n",
        "            'iterations': trial.suggest_int('iterations', 30, MAX_ITERATIONS),\n",
        "            'depth': trial.suggest_int('depth', 3, 7),\n",
        "            'learning_rate': trial.suggest_float('learning_rate', 0.05, 0.2),\n",
        "            'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 5),\n",
        "            'bootstrap_type': trial.suggest_categorical('bootstrap_type', ['Bayesian', 'Bernoulli']),\n",
        "            'random_strength': trial.suggest_float('random_strength', 0.5, 1.5),\n",
        "        }\n",
        "        \n",
        "        # Bootstrap-specific parameters\n",
        "        if params['bootstrap_type'] == 'Bayesian':\n",
        "            params['bagging_temperature'] = trial.suggest_float('bagging_temperature', 0.5, 1.0)\n",
        "        elif params['bootstrap_type'] == 'Bernoulli':\n",
        "            params['subsample'] = trial.suggest_float('subsample', 0.7, 1.0)\n",
        "        \n",
        "        # 2-fold CV to reduce computation time\n",
        "        skf = StratifiedKFold(n_splits=2, shuffle=True, random_state=RANDOM_STATE)\n",
        "        cv_log_losses = []\n",
        "        \n",
        "        y_train_flat = np.array(y_train_encoded).ravel()\n",
        "        \n",
        "        for train_idx, valid_idx in skf.split(X_train, y_train_flat):\n",
        "            X_tr, X_va = X_train.iloc[train_idx], X_train.iloc[valid_idx]\n",
        "            y_tr = y_train_flat[train_idx]\n",
        "            y_va = y_train_flat[valid_idx]\n",
        "            \n",
        "            # Create fresh model for each fold\n",
        "            fold_model = CatBoostClassifier(\n",
        "                loss_function='MultiClass',\n",
        "                random_seed=RANDOM_STATE,\n",
        "                verbose=False,\n",
        "                cat_features=cat_features_indices if cat_features_indices else None,\n",
        "                early_stopping_rounds=5,\n",
        "                iterations=params['iterations'],\n",
        "                **{k: v for k, v in params.items() if k != 'iterations'}\n",
        "            )\n",
        "            \n",
        "            fold_model.fit(X_tr, y_tr, verbose=False)\n",
        "            proba_va = fold_model.predict_proba(X_va)\n",
        "            cv_log_losses.append(log_loss(y_va, proba_va))\n",
        "        \n",
        "        return np.mean(cv_log_losses)\n",
        "    \n",
        "    try:\n",
        "        # TPE sampler for Bayesian optimization\n",
        "        catboost_study = optuna.create_study(\n",
        "            direction='minimize',\n",
        "            study_name='catboost_crocodiles_opt',\n",
        "            sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE)\n",
        "        )\n",
        "        catboost_study.optimize(catboost_objective, n_trials=N_TRIALS_CAT, show_progress_bar=False)\n",
        "        \n",
        "        print(\"\\nBest trial:\")\n",
        "        print(f\"Best CV log loss: {catboost_study.best_trial.value:.4f}\")\n",
        "        print(\"Best parameters:\")\n",
        "        print(catboost_study.best_trial.params)\n",
        "        \n",
        "        # Train final model with best parameters\n",
        "        best_catboost_params = catboost_study.best_trial.params.copy()\n",
        "        # Handle bootstrap-specific params\n",
        "        bootstrap_type = best_catboost_params.pop('bootstrap_type', 'Bayesian')\n",
        "        if 'bagging_temperature' in best_catboost_params:\n",
        "            best_catboost_params['bootstrap_type'] = 'Bayesian'\n",
        "        elif 'subsample' in best_catboost_params:\n",
        "            best_catboost_params['bootstrap_type'] = 'Bernoulli'\n",
        "        else:\n",
        "            best_catboost_params['bootstrap_type'] = bootstrap_type\n",
        "        \n",
        "        # Limit final model iterations\n",
        "        if 'iterations' in best_catboost_params:\n",
        "            best_catboost_params['iterations'] = min(best_catboost_params['iterations'], 100)\n",
        "        \n",
        "        catboost_tuned = CatBoostClassifier(\n",
        "            loss_function='MultiClass',\n",
        "            random_seed=RANDOM_STATE,\n",
        "            verbose=False,\n",
        "            cat_features=cat_features_indices if cat_features_indices else None,\n",
        "            early_stopping_rounds=10,\n",
        "            **best_catboost_params\n",
        "        )\n",
        "        \n",
        "        y_train_catboost = np.array(y_train_encoded).ravel()\n",
        "        catboost_tuned.fit(X_train, y_train_catboost, verbose=False)\n",
        "        \n",
        "        # Evaluate tuned model\n",
        "        catboost_tuned_proba = catboost_tuned.predict_proba(X_valid)\n",
        "        catboost_tuned_pred_encoded = catboost_tuned.predict(X_valid)\n",
        "        catboost_tuned_pred = label_encoder.inverse_transform(catboost_tuned_pred_encoded)\n",
        "        \n",
        "        catboost_tuned_logloss = log_loss(y_valid_encoded, catboost_tuned_proba)\n",
        "        catboost_tuned_acc = accuracy_score(y_valid, catboost_tuned_pred)\n",
        "        # Calculate AUC-ROC for multi-class (one-vs-rest macro-averaged)\n",
        "        catboost_tuned_auc = roc_auc_score(y_valid_encoded, catboost_tuned_proba, multi_class='ovr', average='macro')\n",
        "        \n",
        "        print(f\"\\nCatBoost Tuned - Log Loss: {catboost_tuned_logloss:.4f}, Accuracy: {catboost_tuned_acc:.4f}, AUC-ROC: {catboost_tuned_auc:.4f}\")\n",
        "        print(\"\\nConfusion matrix (CatBoost Tuned):\")\n",
        "        print(confusion_matrix(y_valid, catboost_tuned_pred))\n",
        "        print(\"\\nClassification Report:\")\n",
        "        print(classification_report(y_valid, catboost_tuned_pred))\n",
        "        \n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nCatBoost tuning interrupted. Using baseline only.\")\n",
        "        catboost_tuned = None\n",
        "        catboost_tuned_logloss = None\n",
        "        catboost_tuned_acc = None\n",
        "        catboost_tuned_auc = None\n",
        "else:\n",
        "    print(\"CatBoost tuning skipped (SKIP_CATBOOST_TUNING = True). Using baseline only.\")\n",
        "    catboost_tuned = None\n",
        "    catboost_tuned_logloss = None\n",
        "    catboost_tuned_acc = None\n",
        "    catboost_tuned_auc = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature Importance Analysis\n",
        "print(\"=\"*70)\n",
        "print(\"CATBOOST FEATURE IMPORTANCE ANALYSIS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# CatBoost baseline feature importance\n",
        "if catboost_baseline is not None:\n",
        "    catboost_baseline_importance = catboost_baseline.get_feature_importance()\n",
        "    \n",
        "    catboost_baseline_importance_df = pd.DataFrame({\n",
        "        'Feature': [X_train.columns[i] if i < len(X_train.columns) else f'Feature_{i}' \n",
        "                   for i in range(len(catboost_baseline_importance))],\n",
        "        'CatBoost_Baseline_Importance': catboost_baseline_importance\n",
        "    }).sort_values('CatBoost_Baseline_Importance', ascending=False)\n",
        "    \n",
        "    print(\"\\nTop 15 Most Important Features (CatBoost Baseline):\")\n",
        "    print(catboost_baseline_importance_df.head(15)[['Feature', 'CatBoost_Baseline_Importance']].to_string(index=False))\n",
        "    \n",
        "    # Plot baseline importance\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    top_baseline = catboost_baseline_importance_df.head(15)\n",
        "    plt.barh(range(len(top_baseline)), top_baseline['CatBoost_Baseline_Importance'].values[::-1])\n",
        "    plt.yticks(range(len(top_baseline)), top_baseline['Feature'].values[::-1], fontsize=9)\n",
        "    plt.xlabel('Feature Importance', fontsize=11)\n",
        "    plt.title('Top 15 Features - CatBoost Baseline', fontsize=12, fontweight='bold')\n",
        "    plt.grid(axis='x', alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# CatBoost tuned feature importance if available\n",
        "if 'catboost_tuned' in locals() and catboost_tuned is not None:\n",
        "    catboost_tuned_importance = catboost_tuned.get_feature_importance()\n",
        "    \n",
        "    catboost_tuned_importance_df = pd.DataFrame({\n",
        "        'Feature': [X_train.columns[i] if i < len(X_train.columns) else f'Feature_{i}' \n",
        "                   for i in range(len(catboost_tuned_importance))],\n",
        "        'CatBoost_Tuned_Importance': catboost_tuned_importance\n",
        "    }).sort_values('CatBoost_Tuned_Importance', ascending=False)\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"Top 15 Most Important Features (CatBoost Tuned):\")\n",
        "    print(catboost_tuned_importance_df.head(15)[['Feature', 'CatBoost_Tuned_Importance']].to_string(index=False))\n",
        "    \n",
        "    # Plot tuned importance\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    top_tuned = catboost_tuned_importance_df.head(15)\n",
        "    plt.barh(range(len(top_tuned)), top_tuned['CatBoost_Tuned_Importance'].values[::-1])\n",
        "    plt.yticks(range(len(top_tuned)), top_tuned['Feature'].values[::-1], fontsize=9)\n",
        "    plt.xlabel('Feature Importance', fontsize=11)\n",
        "    plt.title('Top 15 Features - CatBoost Tuned', fontsize=12, fontweight='bold')\n",
        "    plt.grid(axis='x', alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Comparison plot if both available\n",
        "    if catboost_baseline is not None:\n",
        "        # Merge for comparison\n",
        "        comparison_df = catboost_baseline_importance_df.merge(\n",
        "            catboost_tuned_importance_df, on='Feature', how='inner'\n",
        "        ).head(10)\n",
        "        \n",
        "        plt.figure(figsize=(12, 8))\n",
        "        x_pos = np.arange(len(comparison_df))\n",
        "        width = 0.35\n",
        "        \n",
        "        plt.barh(x_pos - width/2, comparison_df['CatBoost_Baseline_Importance'].values, \n",
        "                 width, label='Baseline', alpha=0.8)\n",
        "        plt.barh(x_pos + width/2, comparison_df['CatBoost_Tuned_Importance'].values, \n",
        "                 width, label='Tuned', alpha=0.8)\n",
        "        plt.yticks(x_pos, comparison_df['Feature'].values, fontsize=9)\n",
        "        plt.xlabel('Feature Importance', fontsize=11)\n",
        "        plt.title('Feature Importance: Baseline vs Tuned', fontsize=12, fontweight='bold')\n",
        "        plt.legend()\n",
        "        plt.grid(axis='x', alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Feature importance analysis complete.\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model Comparison and Results Summary\n",
        "print(\"=\"*70)\n",
        "print(\"CATBOOST MODEL PERFORMANCE SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Build results list\n",
        "results_list = []\n",
        "\n",
        "# Add baseline model\n",
        "results_list.append({\n",
        "    'Model': 'CatBoost Baseline',\n",
        "    'Log Loss': catboost_baseline_logloss,\n",
        "    'Accuracy': catboost_baseline_acc,\n",
        "    'AUC-ROC': catboost_baseline_auc,\n",
        "    'Notes': 'Default hyperparameters'\n",
        "})\n",
        "\n",
        "# Add tuned model if available\n",
        "if 'catboost_tuned_logloss' in locals() and catboost_tuned_logloss is not None:\n",
        "    results_list.append({\n",
        "        'Model': 'CatBoost Tuned (Optuna)',\n",
        "        'Log Loss': catboost_tuned_logloss,\n",
        "        'Accuracy': catboost_tuned_acc,\n",
        "        'AUC-ROC': catboost_tuned_auc if 'catboost_tuned_auc' in locals() and catboost_tuned_auc is not None else None,\n",
        "        'Notes': 'Bayesian optimized hyperparameters'\n",
        "    })\n",
        "\n",
        "results_summary = pd.DataFrame(results_list)\n",
        "\n",
        "print(\"\\nResults Table (sorted by Accuracy):\")\n",
        "results_sorted = results_summary.sort_values('Accuracy', ascending=False)\n",
        "print(results_sorted.to_string(index=False))\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"KEY OBSERVATIONS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Find best models\n",
        "best_acc_model = results_summary.loc[results_summary['Accuracy'].idxmax()]\n",
        "best_logloss_model = results_summary.loc[results_summary['Log Loss'].idxmin()]\n",
        "if 'AUC-ROC' in results_summary.columns:\n",
        "    best_auc_model = results_summary.loc[results_summary['AUC-ROC'].idxmax()]\n",
        "\n",
        "print(f\"\\n1. Best Accuracy: {best_acc_model['Model']} ({best_acc_model['Accuracy']:.2%})\")\n",
        "print(f\"2. Best Log Loss: {best_logloss_model['Model']} ({best_logloss_model['Log Loss']:.4f})\")\n",
        "if 'AUC-ROC' in results_summary.columns:\n",
        "    print(f\"3. Best AUC-ROC: {best_auc_model['Model']} ({best_auc_model['AUC-ROC']:.4f})\")\n",
        "\n",
        "print(f\"\\n4. CatBoost Baseline: {catboost_baseline_acc:.2%} accuracy, {catboost_baseline_logloss:.4f} log loss, {catboost_baseline_auc:.4f} AUC-ROC\")\n",
        "\n",
        "if 'catboost_tuned_logloss' in locals() and catboost_tuned_logloss is not None:\n",
        "    print(f\"5. CatBoost Tuned: {catboost_tuned_acc:.2%} accuracy, {catboost_tuned_logloss:.4f} log loss, {catboost_tuned_auc:.4f} AUC-ROC\")\n",
        "    improvement_acc = catboost_tuned_acc - catboost_baseline_acc\n",
        "    improvement_logloss = catboost_baseline_logloss - catboost_tuned_logloss\n",
        "    improvement_auc = catboost_tuned_auc - catboost_baseline_auc if 'catboost_tuned_auc' in locals() and catboost_tuned_auc is not None else 0\n",
        "    if improvement_acc > 0:\n",
        "        print(f\"   -> Tuning improved accuracy by {improvement_acc:.2%}\")\n",
        "    else:\n",
        "        print(f\"   -> Tuning decreased accuracy by {abs(improvement_acc):.2%}\")\n",
        "    if improvement_logloss > 0:\n",
        "        print(f\"   -> Tuning improved log loss by {improvement_logloss:.4f}\")\n",
        "    else:\n",
        "        print(f\"   -> Tuning increased log loss by {abs(improvement_logloss):.4f}\")\n",
        "    if improvement_auc > 0:\n",
        "        print(f\"   -> Tuning improved AUC-ROC by {improvement_auc:.4f}\")\n",
        "    elif improvement_auc < 0:\n",
        "        print(f\"   -> Tuning decreased AUC-ROC by {abs(improvement_auc):.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Note: Compare these results with XGBoost implementation for algorithm comparison.\")\n",
        "print(\"=\"*70)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
